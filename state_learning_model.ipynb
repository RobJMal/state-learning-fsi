{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random \n",
    "\n",
    "from model import Pixel2StateNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", DEVICE)\n",
    "BATCH_SIZE = 32  \n",
    "NUM_EPOCHS = 20\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed) -> None:\n",
    "    '''\n",
    "    Sets the seed for the environment for reproducibility.\n",
    "    '''\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_state_space(state_space):\n",
    "    '''\n",
    "    Converts the OrderedDict to a single vector for the state\n",
    "    space. This is for ease of processing when fed into the model. \n",
    "\n",
    "    Original dict =  \n",
    "    data = OrderedDict([\n",
    "        ('joint_angles', array([7 entries]),\n",
    "        ('upright', 1 entry),\n",
    "        ('target', array([3 entries])),\n",
    "        ('velocity', array([13 entries]))\n",
    "    ])\n",
    "    '''\n",
    "    arrays_list = []\n",
    "    for key, value in state_space.items():\n",
    "        if isinstance(value, np.ndarray):\n",
    "            arrays_list.append(value)\n",
    "        else:\n",
    "            arrays_list.append(np.array([value]))\n",
    "\n",
    "    vector = np.concatenate(arrays_list)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "Converting to pandas dataframe\n",
      "Converting state_space column of dataframe\n",
      "                                               image  \\\n",
      "0  [[[25, 52, 77], [25, 52, 77], [25, 52, 77], [2...   \n",
      "1  [[[25, 52, 77], [25, 52, 77], [25, 52, 77], [2...   \n",
      "2  [[[25, 52, 77], [25, 52, 77], [25, 52, 77], [2...   \n",
      "3  [[[25, 52, 77], [25, 52, 77], [25, 52, 77], [2...   \n",
      "4  [[[25, 52, 77], [25, 52, 77], [25, 52, 77], [2...   \n",
      "\n",
      "                                         state_space  \n",
      "0  [-0.2574390085273436, 0.0009264072188474451, 0...  \n",
      "1  [-0.027611403723891537, 0.0414119146556137, -0...  \n",
      "2  [-0.1885185001670155, 0.08072699084908999, 0.1...  \n",
      "3  [-0.21707487284132598, 0.05409772032614757, 0....  \n",
      "4  [-0.42672974533903885, 0.05006412443187066, 0....  \n"
     ]
    }
   ],
   "source": [
    "set_seed(seed=SEED)\n",
    "\n",
    "# Loading data\n",
    "dataset_path_and_file = \"dataset/augmented_camera_view/proprio_pixel_dataset-100k_2024-06-02_17-44-33.npz\" \n",
    "\n",
    "print(\"Loading dataset\")\n",
    "dataset = np.load(dataset_path_and_file, allow_pickle=True)\n",
    "dataset_images = dataset['frames']\n",
    "dataset_proprios = dataset['observations']\n",
    "\n",
    "# Converting to pandas dataframe \n",
    "print(\"Converting to pandas dataframe\")\n",
    "data = {\n",
    "    'image': list(dataset_images),\n",
    "    'state_space': list(dataset_proprios)\n",
    "}\n",
    "dataset_df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Converting state_space column of dataframe\")\n",
    "dataset_df['state_space'] = dataset_df['state_space'].apply(lambda x: concatenate_state_space(x))\n",
    "\n",
    "print(dataset_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (images) set size: (80000, 128, 128, 3)\n",
      "Training (state_space) set size: (80000, 24)\n",
      "Test (images) set size: (20000, 128, 128, 3)\n",
      "Test (state_space) set size: (20000, 24)\n"
     ]
    }
   ],
   "source": [
    "# CREATING TRAINING AND TEST DATASET\n",
    "images_train, images_test, state_space_train, state_space_test = train_test_split(dataset_df['image'].tolist(),\n",
    "                                                                                  dataset_df['state_space'].tolist(), \n",
    "                                                                                  test_size=0.2, \n",
    "                                                                                  random_state=SEED)\n",
    "\n",
    "# Convert lists back to numpy arrays for ease of use\n",
    "images_train = np.array(images_train)\n",
    "images_test = np.array(images_test)\n",
    "state_space_train = np.array(state_space_train)\n",
    "state_space_test = np.array(state_space_test)\n",
    "\n",
    "print(\"Training (images) set size:\", images_train.shape)\n",
    "print(\"Training (state_space) set size:\", state_space_train.shape)\n",
    "print(\"Test (images) set size:\", images_test.shape)\n",
    "print(\"Test (state_space) set size:\", state_space_test.shape)\n",
    "\n",
    "del dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature map size:  9216\n"
     ]
    }
   ],
   "source": [
    "model = Pixel2StateNet()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "train_losses, train_error = [], []\n",
    "val_losses, val_error = [], []\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss_train = 0\n",
    "    abs_errors = 0\n",
    "    sample_num_train = 0\n",
    "    i = 0\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsi_py39_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
